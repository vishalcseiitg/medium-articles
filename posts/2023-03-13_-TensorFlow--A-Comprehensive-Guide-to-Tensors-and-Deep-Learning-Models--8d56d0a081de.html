<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>“TensorFlow: A Comprehensive Guide to Tensors and Deep Learning Models”</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">“TensorFlow: A Comprehensive Guide to Tensors and Deep Learning Models”</h1>
</header>
<section data-field="subtitle" class="p-summary">
Tensors are a fundamental concept in mathematics and physics, and they play a critical role in describing the behavior of physical systems…
</section>
<section data-field="body" class="e-content">
<section name="c6d8" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="c09c" id="c09c" class="graf graf--h3 graf--startsWithDoubleQuote graf--leading graf--title">“TensorFlow: A Comprehensive Guide to Tensors and Deep Learning Models”</h3><figure name="67ac" id="67ac" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*LPVcOvGvE1hIFzkyD4bc4A.png" data-width="1720" data-height="900" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*LPVcOvGvE1hIFzkyD4bc4A.png"><figcaption class="imageCaption"><a href="https://www.toptal.com/machine-learning/tensorflow-python-tutorial" data-href="https://www.toptal.com/machine-learning/tensorflow-python-tutorial" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">TensorFlow</a></figcaption></figure><p name="9ab8" id="9ab8" class="graf graf--p graf-after--figure">Tensors are a fundamental concept in mathematics and physics, and they play a critical role in describing the behavior of physical systems in a mathematical framework. A tensor is a mathematical object representing physical quantities with multiple components, such as velocity, acceleration, and stress. These components can be scalar values, vectors, or matrices and can change as the physical system evolves. Tensors are widely used in various fields, including mechanics, electromagnetism, relativity, computer graphics, and machine learning. Understanding tensors is essential for anyone interested in these fields, as they provide a powerful tool for modeling and analyzing complex physical systems.</p><p name="8101" id="8101" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">There are three types of tensors: scalars, vectors, and matrices.</strong></p><p name="c0a7" id="c0a7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Scalars</strong>: A scalar is a quantity that has only one component, such as temperature, mass, or charge. Scalars are represented by a single number and are often used as a basis for defining other types of tensors. For example, a vector is a quantity with both magnitude and direction, but it can be represented as a scalar by taking its magnitude.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="014d" id="014d" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># Define a scalar variable</span><br />temperature = <span class="hljs-number">25.5</span><br /><br /><span class="hljs-comment"># Print the scalar value</span><br /><span class="hljs-built_in">print</span>(temperature)</span></pre><p name="7eb4" id="7eb4" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Vectors</strong>: A vector is a quantity that has both magnitude and direction. Vectors are represented by an ordered set of numbers, or components, that describe their magnitude and direction. Examples of vector quantities include velocity, force, and electric field. Vectors are often used to describe physical quantities with a direction, such as the displacement of an object or the force acting on it.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="d79e" id="d79e" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># Import the NumPy library for working with vectors</span><br /><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br /><br /><span class="hljs-comment"># Define a vector as a NumPy array</span><br />velocity = np.array([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>])<br /><br /><span class="hljs-comment"># Print the vector</span><br /><span class="hljs-built_in">print</span>(velocity)</span></pre><p name="8bfc" id="8bfc" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Matrices</strong>: A matrix is a quantity with multiple components arranged in a rectangular array. Matrices are represented by a set of numbers arranged in rows and columns. They can be used to represent a variety of physical quantities, such as stress, strain, and deformation. Matrices are often used to describe the behavior of physical systems in which multiple quantities interact. For example, a stress tensor is a matrix that describes the distribution of stresses in a material under deformation.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="47f6" id="47f6" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># Import the NumPy library for working with matrices</span><br /><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br /><br /><span class="hljs-comment"># Define a matrix as a NumPy array</span><br />stress_tensor = np.array([[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">0.5</span>],<br />                          [<span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">0.0</span>],<br />                          [<span class="hljs-number">0.5</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">2.0</span>]])<br /><br /><span class="hljs-comment"># Print the matrix</span><br /><span class="hljs-built_in">print</span>(stress_tensor)</span></pre><p name="5cb9" id="5cb9" class="graf graf--p graf-after--pre">In addition to these three types of tensors, there are higher-order tensors with more than two dimensions. Higher-order tensors are less commonly used than scalars, vectors, and matrices but can describe more complex physical systems. Examples of higher-order tensors include tensors used in fluid mechanics, which have three or more dimensions to describe the behavior of fluids.</p><p name="b4d4" id="b4d4" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Tensors in Machine Learning:</strong></p><p name="5d97" id="5d97" class="graf graf--p graf-after--p">In machine learning, tensors are used as a fundamental data structure for representing inputs, outputs, and intermediate data within algorithms. Tensors are multi-dimensional arrays that can hold numerical data, such as images, text, and audio signals. The dimensions of a tensor are referred to as its shape, which can be used to describe the size and structure of the data it contains.</p><p name="8968" id="8968" class="graf graf--p graf-after--p">Tensors are also used to represent parameters in machine learning algorithms. Parameters are values that are learned during training and used to make predictions. Examples of parameters include weights and biases in neural networks. These parameters are typically stored as tensors and updated during training using techniques such as backpropagation.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="bd6f" id="bd6f" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># Import TensorFlow library</span><br /><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br /><br /><span class="hljs-comment"># Define a tensor as a constant value</span><br />x = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br /><br /><span class="hljs-comment"># Print the tensor</span><br /><span class="hljs-built_in">print</span>(x)</span></pre><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="go" name="1fac" id="1fac" class="graf graf--pre graf-after--pre graf--preV2"><span class="pre--content">tf.Tensor([<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>], shape=(<span class="hljs-number">3</span>,), dtype=<span class="hljs-type">int32</span>)</span></pre><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="310a" id="310a" class="graf graf--pre graf-after--pre graf--preV2"><span class="pre--content"><span class="hljs-comment"># Define two tensors</span><br />a = tf.constant([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])<br />b = tf.constant([[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br /><br /><span class="hljs-comment"># Perform matrix multiplication</span><br />c = tf.matmul(a, b)<br /><br /><span class="hljs-comment"># Print the result</span><br /><span class="hljs-built_in">print</span>(c)</span></pre><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="627b" id="627b" class="graf graf--pre graf-after--pre graf--preV2"><span class="pre--content">tf.Tensor(<br />[[<span class="hljs-number">19</span> <span class="hljs-number">22</span>]<br /> [<span class="hljs-number">43</span> <span class="hljs-number">50</span>]], shape=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dtype=int32)</span></pre><p name="1805" id="1805" class="graf graf--p graf-after--pre">Tensors perform various operations in machine learning algorithms, such as matrix multiplication, convolution, and pooling. Matrix multiplication is used to perform linear transformations and can be used to represent the transformations performed by neural networks. Convolution is used in convolutional neural networks (CNNs) to extract features from images by sliding a small kernel over the image and computing the dot product with the image patch at each location. Pooling is used to downsample the feature maps produced by CNNs by taking the maximum or average value within each pooling region.</p><p name="c6dd" id="c6dd" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Usage in Machine Learning:</strong></p><ol class="postList"><li name="9b7f" id="9b7f" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Image classification using CNNs</strong>: In image classification tasks, CNNs are commonly used to extract features from images and classify them into different categories. Tensors are used to represent the images and the parameters of the CNN model. The input image tensor typically has dimensions (height, width, channels), while the output tensor represents the predicted probabilities of each class.</li></ol><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="b856" id="b856" class="graf graf--pre graf-after--li graf--preV2"><span class="pre--content"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br /><span class="hljs-keyword">from</span> tensorflow.keras.datasets <span class="hljs-keyword">import</span> mnist<br /><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Conv2D, MaxPooling2D, Flatten, Dense<br /><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential<br /><span class="hljs-keyword">from</span> tensorflow.keras.utils <span class="hljs-keyword">import</span> to_categorical<br /><br /><span class="hljs-comment"># Load the MNIST dataset and preprocess the data</span><br />(x_train, y_train), (x_test, y_test) = mnist.load_data()<br />x_train = x_train.reshape((<span class="hljs-number">60000</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>)).astype(<span class="hljs-string">&#x27;float32&#x27;</span>) / <span class="hljs-number">255</span><br />x_test = x_test.reshape((<span class="hljs-number">10000</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>)).astype(<span class="hljs-string">&#x27;float32&#x27;</span>) / <span class="hljs-number">255</span><br />y_train = to_categorical(y_train)<br />y_test = to_categorical(y_test)<br /><br /><span class="hljs-comment"># Define the CNN model architecture</span><br />model = Sequential()<br />model.add(Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&#x27;relu&#x27;</span>, input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>)))<br />model.add(MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<br />model.add(Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br />model.add(MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<br />model.add(Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br />model.add(Flatten())<br />model.add(Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br />model.add(Dense(<span class="hljs-number">10</span>, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>))<br /><br /><span class="hljs-comment"># Compile the model and define the loss function and optimizer</span><br />model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br /><br /><span class="hljs-comment"># Train the model on the training data</span><br />model.fit(x_train, y_train, epochs=<span class="hljs-number">5</span>, batch_size=<span class="hljs-number">64</span>, validation_data=(x_test, y_test))<br /><br /><span class="hljs-comment"># Evaluate the model on the test data</span><br />test_loss, test_acc = model.evaluate(x_test, y_test)<br /><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Test accuracy:&#x27;</span>, test_acc)</span></pre><ul class="postList"><li name="aecf" id="aecf" class="graf graf--li graf-after--pre"><code class="markup--code markup--li-code">from tensorflow.keras.datasets import mnist</code>: This line imports the MNIST dataset from TensorFlow.</li><li name="825b" id="825b" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">x_train = x_train.reshape((60000, 28, 28, 1)).astype(&#39;float32&#39;) / 255</code> and <code class="markup--code markup--li-code">x_test = x_test.reshape((10000, 28, 28, 1)).astype(&#39;float32&#39;) / 255</code>: These lines reshape the input image tensors to have dimensions (height, width, channels) and normalize the pixel values between 0 and 1.</li><li name="c067" id="c067" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">y_train = to_categorical(y_train)</code> and <code class="markup--code markup--li-code">y_test = to_categorical(y_test)</code>: These lines convert the target labels to one-hot encoded vectors.</li><li name="75f2" id="75f2" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model = Sequential()</code>: This line creates a sequential model.</li><li name="0143" id="0143" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.add(Conv2D(32, (3, 3), activation=&#39;relu&#39;, input_shape=(28, 28, 1)))</code>: This line adds a 2D convolutional layer with 32 filters, a filter size of 3x3, a ReLU activation function, and an input shape of (28, 28, 1).</li><li name="7f04" id="7f04" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.add(MaxPooling2D((2, 2)))</code>: This line adds a max pooling layer with a pool size of 2x2.</li><li name="03f4" id="03f4" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.add(Conv2D(64, (3, 3), activation=&#39;relu&#39;))</code>: This line adds another 2D convolutional layer with 64 filters and a filter size of 3x3.</li><li name="3eb1" id="3eb1" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.add(Flatten())</code>: This line flattens the output tensor from the convolutional layers into a 1D vector.</li><li name="33af" id="33af" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.add(Dense(64, activation=&#39;relu&#39;))</code>: This line adds a fully connected layer with 64 units and a ReLU activation function.</li><li name="4d8a" id="4d8a" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])</code>: This line compiles the model with the Adam optimizer and binary cross-entropy loss function for binary classification.</li><li name="4dd8" id="4dd8" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))</code>: This line trains the model on the training data for 5 epochs with a batch size of 64 and evaluates the model on the validation data after each epoch.</li><li name="4b17" id="4b17" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">test_loss, test_acc = model.evaluate(x_test, y_test)</code>: This line evaluates the model on the test data and returns the test loss and accuracy.</li><li name="915f" id="915f" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">print(&#39;Test accuracy:&#39;, test_acc)</code>: This line prints the test accuracy.</li></ul><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="yaml" name="bf4a" id="bf4a" class="graf graf--pre graf-after--li graf--preV2"><span class="pre--content"><span class="hljs-string">Downloading</span> <span class="hljs-string">data</span> <span class="hljs-string">from</span> <span class="hljs-string">https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz</span><br /><span class="hljs-number">11490434</span><span class="hljs-string">/11490434</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-string">0s</span> <span class="hljs-string">0us/step</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">1</span><span class="hljs-string">/5</span><br /><span class="hljs-number">938</span><span class="hljs-string">/938</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">34s 35ms/step - loss: 0.1900 - accuracy: 0.9416 - val_loss: 0.0572 - val_accuracy:</span> <span class="hljs-number">0.9820</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">2</span><span class="hljs-string">/5</span><br /><span class="hljs-number">938</span><span class="hljs-string">/938</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">32s 34ms/step - loss: 0.0511 - accuracy: 0.9838 - val_loss: 0.0361 - val_accuracy:</span> <span class="hljs-number">0.9878</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">3</span><span class="hljs-string">/5</span><br /><span class="hljs-number">938</span><span class="hljs-string">/938</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">32s 34ms/step - loss: 0.0371 - accuracy: 0.9884 - val_loss: 0.0305 - val_accuracy:</span> <span class="hljs-number">0.9901</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">4</span><span class="hljs-string">/5</span><br /><span class="hljs-number">938</span><span class="hljs-string">/938</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">31s 33ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0252 - val_accuracy:</span> <span class="hljs-number">0.9920</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">5</span><span class="hljs-string">/5</span><br /><span class="hljs-number">938</span><span class="hljs-string">/938</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">31s 33ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0303 - val_accuracy:</span> <span class="hljs-number">0.9901</span><br /><span class="hljs-number">313</span><span class="hljs-string">/313</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">2s 7ms/step - loss: 0.0303 - accuracy:</span> <span class="hljs-number">0.9901</span><br /><span class="hljs-attr">Test accuracy:</span> <span class="hljs-number">0.9901000261306763</span></span></pre><p name="a5c5" id="a5c5" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">2. Natural language processing using RNNs</strong>: In natural language processing tasks such as text classification and language modeling, recurrent neural networks (RNNs) are commonly used to model the sequential nature of text data. Tensors are used to represent the text data and the parameters of the RNN model. The input tensor typically has dimensions (sequence length, embedding dimension), while the output tensor represents the predicted probabilities of each class.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="1396" id="1396" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br /><span class="hljs-keyword">from</span> tensorflow.keras.datasets <span class="hljs-keyword">import</span> imdb<br /><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Embedding, LSTM, Dense<br /><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential<br /><span class="hljs-keyword">from</span> tensorflow.keras.preprocessing <span class="hljs-keyword">import</span> sequence<br /><br /><span class="hljs-comment"># Load the IMDB dataset and preprocess the data</span><br />(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=<span class="hljs-number">10000</span>)<br />x_train = sequence.pad_sequences(x_train, maxlen=<span class="hljs-number">200</span>)<br />x_test = sequence.pad_sequences(x_test, maxlen=<span class="hljs-number">200</span>)<br /><br /><span class="hljs-comment"># Define the RNN model architecture</span><br />model = Sequential()<br />model.add(Embedding(input_dim=<span class="hljs-number">10000</span>, output_dim=<span class="hljs-number">128</span>, input_length=<span class="hljs-number">200</span>))<br />model.add(LSTM(units=<span class="hljs-number">64</span>))<br />model.add(Dense(units=<span class="hljs-number">1</span>, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>))<br /><br /><span class="hljs-comment"># Compile the model and define the loss function and optimizer</span><br />model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, loss=<span class="hljs-string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br /><br /><span class="hljs-comment"># Train the model on the training data</span><br />model.fit(x_train, y_train, epochs=<span class="hljs-number">5</span>, batch_size=<span class="hljs-number">64</span>, validation_data=(x_test, y_test))<br /><br /><span class="hljs-comment"># Evaluate the model on the test data</span><br />test_loss, test_acc = model.evaluate(x_test, y_test)<br /><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Test accuracy:&#x27;</span>, test_acc)</span></pre><ul class="postList"><li name="1c6f" id="1c6f" class="graf graf--li graf-after--pre"><code class="markup--code markup--li-code">from tensorflow.keras.datasets import imdb</code>: This line imports the IMDB dataset from TensorFlow.</li><li name="b557" id="b557" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">x_train = sequence.pad_sequences(x_train, maxlen=200)</code> and <code class="markup--code markup--li-code">x_test = sequence.pad_sequences(x_test, maxlen=200)</code>: These lines pad the input text tensors with zeros for a fixed sequence length of 200.</li><li name="96de" id="96de" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model = Sequential()</code>: This line creates a sequential model.</li><li name="d04a" id="d04a" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.add(Embedding(input_dim=10000, output_dim=128, input_length=200))</code>: This line adds an embedding layer with an input dimension of 10000, an embedding dimension of 128, and an input length of 200.</li><li name="30a0" id="30a0" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.add(LSTM(units=64))</code>: This line adds an LSTM layer with 64 units.</li><li name="9013" id="9013" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.add(Dense(units=1, activation=&#39;sigmoid&#39;))</code>: This line adds a fully connected layer with 1 unit and a sigmoid activation function.</li><li name="5613" id="5613" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])</code>: This line compiles the model with the Adam optimizer and binary cross-entropy loss function for binary classification.</li><li name="d5a5" id="d5a5" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))</code>: This line trains the model on the training data for 5 epochs with a batch size of 64 and evaluates the model on the validation data after each epoch.</li><li name="5c83" id="5c83" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">test_loss, test_acc = model.evaluate(x_test, y_test)</code>: This line evaluates the model on the test data and returns the test loss and accuracy.</li><li name="947a" id="947a" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">print(&#39;Test accuracy:&#39;, test_acc)</code>: This line prints the test accuracy.</li></ul><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="yaml" name="6968" id="6968" class="graf graf--pre graf-after--li graf--preV2"><span class="pre--content"><span class="hljs-string">Downloading</span> <span class="hljs-string">data</span> <span class="hljs-string">from</span> <span class="hljs-string">https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz</span><br /><span class="hljs-number">17464789</span><span class="hljs-string">/17464789</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-string">0s</span> <span class="hljs-string">0us/step</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">1</span><span class="hljs-string">/5</span><br /><span class="hljs-number">391</span><span class="hljs-string">/391</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">112s 279ms/step - loss: 0.3908 - accuracy: 0.8196 - val_loss: 0.3072 - val_accuracy:</span> <span class="hljs-number">0.8711</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">2</span><span class="hljs-string">/5</span><br /><span class="hljs-number">391</span><span class="hljs-string">/391</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">89s 227ms/step - loss: 0.2290 - accuracy: 0.9096 - val_loss: 0.3262 - val_accuracy:</span> <span class="hljs-number">0.8709</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">3</span><span class="hljs-string">/5</span><br /><span class="hljs-number">391</span><span class="hljs-string">/391</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">89s 228ms/step - loss: 0.1702 - accuracy: 0.9370 - val_loss: 0.3508 - val_accuracy:</span> <span class="hljs-number">0.8676</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">4</span><span class="hljs-string">/5</span><br /><span class="hljs-number">391</span><span class="hljs-string">/391</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">89s 229ms/step - loss: 0.1264 - accuracy: 0.9549 - val_loss: 0.3728 - val_accuracy:</span> <span class="hljs-number">0.8568</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">5</span><span class="hljs-string">/5</span><br /><span class="hljs-number">391</span><span class="hljs-string">/391</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">89s 229ms/step - loss: 0.0894 - accuracy: 0.9694 - val_loss: 0.4359 - val_accuracy:</span> <span class="hljs-number">0.8583</span><br /><span class="hljs-number">782</span><span class="hljs-string">/782</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">27s 35ms/step - loss: 0.4359 - accuracy:</span> <span class="hljs-number">0.8583</span><br /><span class="hljs-attr">Test accuracy:</span> <span class="hljs-number">0.8583199977874756</span></span></pre><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="10b9" id="10b9" class="graf graf--pre graf-after--pre graf--preV2"><span class="pre--content"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br /><span class="hljs-keyword">from</span> tensorflow.keras.datasets <span class="hljs-keyword">import</span> mnist<br /><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential<br /><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dense, Dropout<br /><span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> Adam<br /><br /><span class="hljs-comment"># Load MNIST dataset</span><br />(x_train, y_train), (x_test, y_test) = mnist.load_data()<br /><br /><span class="hljs-comment"># Preprocess data</span><br />x_train = x_train.reshape(<span class="hljs-number">60000</span>, <span class="hljs-number">784</span>).astype(<span class="hljs-string">&#x27;float32&#x27;</span>) / <span class="hljs-number">255.</span><br />x_test = x_test.reshape(<span class="hljs-number">10000</span>, <span class="hljs-number">784</span>).astype(<span class="hljs-string">&#x27;float32&#x27;</span>) / <span class="hljs-number">255.</span><br />y_train = tf.keras.utils.to_categorical(y_train, <span class="hljs-number">10</span>)<br />y_test = tf.keras.utils.to_categorical(y_test, <span class="hljs-number">10</span>)<br /><br /><span class="hljs-comment"># Define model architecture</span><br />model = Sequential([<br />    Dense(<span class="hljs-number">512</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>, input_shape=(<span class="hljs-number">784</span>,)),<br />    Dropout(<span class="hljs-number">0.2</span>),<br />    Dense(<span class="hljs-number">512</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>),<br />    Dropout(<span class="hljs-number">0.2</span>),<br />    Dense(<span class="hljs-number">10</span>, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>)<br />])<br /><br /><span class="hljs-comment"># Compile model</span><br />model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>,<br />              optimizer=Adam(),<br />              metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br /><br /><span class="hljs-comment"># Set up TensorBoard callback</span><br />log_dir = <span class="hljs-string">&quot;logs/fit&quot;</span><br />tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=<span class="hljs-number">1</span>)<br /><br /><span class="hljs-comment"># Train model and log data to TensorBoard</span><br />model.fit(x_train, y_train,<br />          batch_size=<span class="hljs-number">128</span>,<br />          epochs=<span class="hljs-number">20</span>,<br />          verbose=<span class="hljs-number">1</span>,<br />          validation_data=(x_test, y_test),<br />          callbacks=[tensorboard_callback])Conclusion:</span></pre><p name="e575" id="e575" class="graf graf--p graf-after--pre">This code trains a deep-learning model to classify handwritten digits from the MNIST dataset and uses a TensorBoard callback to log training metrics such as loss and accuracy. To view the TensorBoard visualization, you can run the command <code class="markup--code markup--p-code">tensorboard --logdir logs/fit</code> in the terminal and then open the TensorBoard URL in your web browser.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="yaml" name="cfa5" id="cfa5" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-string">Epoch</span> <span class="hljs-number">1</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">9s 17ms/step - loss: 0.2507 - accuracy: 0.9230 - val_loss: 0.0966 - val_accuracy:</span> <span class="hljs-number">0.9704</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">2</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 15ms/step - loss: 0.1029 - accuracy: 0.9684 - val_loss: 0.0866 - val_accuracy:</span> <span class="hljs-number">0.9740</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">3</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 15ms/step - loss: 0.0720 - accuracy: 0.9773 - val_loss: 0.0805 - val_accuracy:</span> <span class="hljs-number">0.9754</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">4</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 16ms/step - loss: 0.0562 - accuracy: 0.9823 - val_loss: 0.0669 - val_accuracy:</span> <span class="hljs-number">0.9796</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">5</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 15ms/step - loss: 0.0449 - accuracy: 0.9858 - val_loss: 0.0680 - val_accuracy:</span> <span class="hljs-number">0.9785</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">6</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 15ms/step - loss: 0.0393 - accuracy: 0.9871 - val_loss: 0.0740 - val_accuracy:</span> <span class="hljs-number">0.9772</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">7</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 16ms/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.0743 - val_accuracy:</span> <span class="hljs-number">0.9791</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">8</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">8s 17ms/step - loss: 0.0303 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy:</span> <span class="hljs-number">0.9807</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">9</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">8s 17ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.0699 - val_accuracy:</span> <span class="hljs-number">0.9813</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">10</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 16ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.0665 - val_accuracy:</span> <span class="hljs-number">0.9839</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">11</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 16ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0702 - val_accuracy:</span> <span class="hljs-number">0.9824</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">12</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 15ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.0735 - val_accuracy:</span> <span class="hljs-number">0.9825</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">13</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 16ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0705 - val_accuracy:</span> <span class="hljs-number">0.9832</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">14</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 15ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0687 - val_accuracy:</span> <span class="hljs-number">0.9830</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">15</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 15ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0699 - val_accuracy:</span> <span class="hljs-number">0.9840</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">16</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 16ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.0826 - val_accuracy:</span> <span class="hljs-number">0.9819</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">17</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">8s 16ms/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 0.0832 - val_accuracy:</span> <span class="hljs-number">0.9818</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">18</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 15ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0867 - val_accuracy:</span> <span class="hljs-number">0.9809</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">19</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 14ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0754 - val_accuracy:</span> <span class="hljs-number">0.9852</span><br /><span class="hljs-string">Epoch</span> <span class="hljs-number">20</span><span class="hljs-string">/20</span><br /><span class="hljs-number">469</span><span class="hljs-string">/469</span> [<span class="hljs-string">==============================</span>] <span class="hljs-bullet">-</span> <span class="hljs-attr">7s 15ms/step - loss: 0.0142 - accuracy: 0.9948 - val_loss: 0.0853 - val_accuracy:</span> <span class="hljs-number">0.9844</span><br /><span class="hljs-string">&lt;keras.callbacks.History</span> <span class="hljs-string">at</span> <span class="hljs-number">0x7fd8936c1e10</span><span class="hljs-string">&gt;</span></span></pre><p name="2fe1" id="2fe1" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">Conclusions:</strong></p><p name="f1e4" id="f1e4" class="graf graf--p graf-after--p graf--trailing">Tensors are a fundamental building block of machine learning algorithms and represent data, models, and computations in various forms. They are multidimensional arrays that can represent complex data structures and enable efficient computation through parallelism and vectorization. This article has explored different examples of how tensors are used in machine learning, including image classification and natural language processing. Understanding tensors and how they are used in machine learning is crucial for anyone interested in working with deep learning models and building sophisticated applications that leverage the power of artificial intelligence.</p></div></div></section><section name="4d13" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="169f" id="169f" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">References</strong>:</p><ul class="postList"><li name="3098" id="3098" class="graf graf--li graf--startsWithDoubleQuote graf-after--p">“Neural Networks and Deep Learning” book by Michael Nielsen</li><li name="285c" id="285c" class="graf graf--li graf--startsWithDoubleQuote graf-after--li">“Python Machine Learning” book by Sebastian Raschka and Vahid Mirjalili</li><li name="49e8" id="49e8" class="graf graf--li graf-after--li">TensorFlow documentation: <a href="https://www.tensorflow.org/api_docs" data-href="https://www.tensorflow.org/api_docs" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">https://www.tensorflow.org/api_docs</a></li><li name="aa05" id="aa05" class="graf graf--li graf-after--li">PyTorch documentation: <a href="https://pytorch.org/docs/stable/index.html" data-href="https://pytorch.org/docs/stable/index.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">https://pytorch.org/docs/stable/index.html</a></li><li name="bf1a" id="bf1a" class="graf graf--li graf-after--li">Keras documentation: <a href="https://keras.io/api/" data-href="https://keras.io/api/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">https://keras.io/api/</a></li><li name="930f" id="930f" class="graf graf--li graf--startsWithDoubleQuote graf-after--li graf--trailing">“Deep Learning with Python” book by François Chollet</li></ul></div></div></section><section name="6521" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="a79a" id="a79a" class="graf graf--p graf--leading graf--trailing"><em class="markup--em markup--p-em">Dear readers, thank you for taking the time to read my article. I hope you found it informative and useful in your pursuit of knowledge. If you enjoyed reading this article and want to see more like it, please follow me and stay updated on my latest posts. Your support means a lot to me and motivates me to continue sharing my knowledge and insights with the world. Thank you again for your time and consideration, and I look forward to sharing more content with you in the future.</em></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@the_daft_introvert" class="p-author h-card">Vishal Sharma</a> on <a href="https://medium.com/p/8d56d0a081de"><time class="dt-published" datetime="2023-03-13T02:16:35.064Z">March 13, 2023</time></a>.</p><p><a href="https://medium.com/@the_daft_introvert/tensorflow-a-comprehensive-guide-to-tensors-and-deep-learning-models-8d56d0a081de" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on April 2, 2023.</p></footer></article></body></html>